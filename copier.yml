# The template root is found here
_subdirectory: template
_envops:
  block_start_string: "{%"
  block_end_string: "%}"
  variable_start_string: "{{"  
  variable_end_string: "}}"
  comment_start_string: "{#"
  comment_end_string: "#}"


_metadata:
  name: "ReproGen"
  description: "ReproGen: A Template Generator for Reproducible Machine Learning Projects on Chameleon Cloud"
  version: "1.0.0"
  author: "cc_team"
  license: "MIT"
  homepage: "https://github.com/a7med7x7/ReproGen"
  repository: "https://github.com/a7med7x7/ReproGen"
  
# Skip overwriting existing files (user can force with --force)
_skip_if_exists:
  - "*.ipynb"
  - "requirements.txt"
  - ".env"
  - "src/**"

# Files to exclude from template rendering (copy as-is)
_templates_suffix_to_ignore:
  - ".jpg"
  - ".png" 
  - ".gif"
  - ".ico"
  - ".pdf"
  - ".zip"
  - ".tar.gz"

__skip_answered: false
  # PROJECT CONFIGURATION

setup_mode:
  type: str
  choices:
    - Basic
    - Advanced
  default: Basic
  help: |
    Choose configuration mode:
    - Basic: minimal options 
    - Advanced: extra settings and flexibility

project_name:
  type: str
  help: |
    Project Name: A unique identifier for your project. This name will be used consistently across your setup, including:

    - Prefixes for S3 buckets (e.g., project-name-data`, project-name-mlflow-artifacts)  
    - Names for compute resources (VMs or bare-metal leases) 

    Rules:
    - May include uppercase or lowercase letters, numbers, hyphen (-), and underscore (_)
    - No spaces allowed
  validator: >-
    {% if not (project_name | regex_search('^[A-Za-z0-9_-]+$')) %}
    Project name may only contain letters (A–Z, a–z), numbers (0–9), hyphen (-), and underscore (_).
    No spaces are allowed.
    {% endif %}

repo_url:
  type: str
  default: ""
  help: |
    Git repository URL for your generated project.
    Recommendations:
      1. Create a repository named exactly after your project-name it will host the generated material.
      2. Paste the repository URL here (HTTPS or SSH).
         Examples:
           - HTTPS: https://github.com/yourname/project-name
           - HTTPS: https://gitlab.com/yourname/project-name
           - SSH: git@bitbucket.org:yourname/project-name.git
  validator: >-
   {% if repo_url and not (repo_url | regex_search('^(https://|git@)[^/:]+[:/][^/]+/[^/]+(\.git)?$')) %}
    Must be a valid Git repository URL (HTTPS or SSH).
    Examples:
      - https://github.com/yourname/repo-name
      - git@gitlab.com:yourname/repo-name.git
    {% endif %}

chameleon_site:
  type: str
  choices:
    - CHI@TACC
    - CHI@UC
    - KVM@TACC
  default: CHI@TACC
  help: |
    Select the site where you want your compute resources(VMs or bare metal) to run.
    This choice does not control where your S3 data buckets are stored — 
    bucket storage location is set separately using the bucket_site option.

    Sites:
    - CHI@TACC: Texas Advanced Computing Center (most GPU bare metal nodes)
    - CHI@UC: University of Chicago
    - KVM@TACC: Texas Advanced Computing Center (virtual machine nodes)
  when: "{{ setup_mode == 'Advanced' }}"

bucket_site:
  type: str
  choices:
    - CHI@TACC
    - CHI@UC
    - auto
  default: CHI@TACC
  help: |
    Location for storing your S3 data buckets:
    - CHI@TACC: Texas Advanced Computing Center
    - CHI@UC: University of Chicago
    - auto: We'll pick the optimal site for you

    Tip: If you're not sure, choose "auto" — it works for most users.
  when: "{{ setup_mode == 'Advanced' }}"

gpu_type:
  type: str
  choices:
    - nvidia    
    - amd          
    - cpu       
  multiselect: true
  default: [nvidia]

  help: |
    GPU type you plan to use for your lease:
    - nvidia: For NVIDIA GPU nodes
    - amd: For AMD GPU nodes
    - any: No preference — use whichever GPU type is available
    - cpu: CPU-only nodes (no GPU, good for classical ML or lightweight workloads)
  when: "{{ setup_mode == 'Advanced' }}"

ml_framework:
  type: str
  choices:
    - pytorch
    - tensorflow
    - data-science
    - pytorch-lightning
  multiselect: true
  help: |
    Primary ML framework for your environment:
    - pytorch: PyTorch with GPU support
    - tensorflow: TensorFlow with GPU support
    - data-science: General data science stack (pandas, sklearn, etc.)

cuda_version:
  type: str
  help: "What CUDA version you plan to use with your Jupyter image (more recent: cuda-12, older legacy GPU compatibility: cuda-11)"
  choices:
    - cuda11-latest
    - cuda12-latest
  when: "{{ ('pytorch' in ml_framework) or ('pytorch-lightning' in ml_framework) and ('nvidia' in gpu_type ) and (setup_mode == 'Advanced')  }}"

include_huggingface:
  type: bool
  default: true
  help: |
    Enable Hugging Face integration?
    This will set up your containerized environment so you can download and use
    models directly from the Hugging Face Hub.

  when: "{{ setup_mode == 'Advanced' }}"